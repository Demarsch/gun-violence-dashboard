{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_schema import engine, Incident, Category, Participant, Statistics, StatisticsValue\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import func, extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_pivots = { 'victimAge', 'victimGender', 'suspectAge', 'suspectGender' }\n",
    "incident_pivots = { 'state', 'year', 'month' }\n",
    "month_names = { '01': 'Jan', '02': 'Feb', '03': 'Mar', '04': 'Apr', '05': 'May', '06': 'Jun',\n",
    "                '07': 'Jul', '08': 'Aug', '09': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec' }\n",
    "\n",
    "stat_group_by_selectors = {\n",
    "    'state': StatisticsValue.state,\n",
    "    'year': StatisticsValue.year\n",
    "}\n",
    "# For some reason retrieving month name as strftime('%b') is not working\n",
    "group_by_converters = {\n",
    "    'year': lambda x: int(x),\n",
    "    'victimGender': lambda x: 'Male' if x else 'Female',\n",
    "    'suspectGender': lambda x: 'Male' if x else 'Female',\n",
    "    'month': lambda x: month_names[x]\n",
    "}\n",
    "\n",
    "group_by_selectors = {\n",
    "    'state': Incident.state,\n",
    "    'year': func.strftime('%Y', Incident.date),\n",
    "    'month': func.strftime('%m', Incident.date),\n",
    "    'victimAge': Participant.age,\n",
    "    'victimGender': Participant.is_male,\n",
    "    'suspectAge': Participant.age,\n",
    "    'suspectGender': Participant.is_male\n",
    "}\n",
    "\n",
    "participant_status_filters = {\n",
    "    'incidents': None,\n",
    "    'killed': (Participant.is_killed, True),\n",
    "    'injured': (Participant.is_killed, False)\n",
    "}\n",
    "\n",
    "participant_type_filters = {\n",
    "    'victimAge': (Participant.is_victim, True),\n",
    "    'victimGender': (Participant.is_victim, True),\n",
    "    'suspectAge': (Participant.is_victim, False),\n",
    "    'suspectGender': (Participant.is_victim, False),\n",
    "}\n",
    "\n",
    "incident_aggregate_selectors = {\n",
    "    'incidents': func.count(),\n",
    "    'killed': func.sum(Incident.n_killed),\n",
    "    'injured': func.sum(Incident.n_injured)\n",
    "}\n",
    "# If we group by year then we need to sum values across all states\n",
    "# If we group by state then we need to get average value across all years\n",
    "stat_aggregate_selectors = {\n",
    "    'state': func.round(func.avg(StatisticsValue.value), 1),\n",
    "    'year': func.sum(StatisticsValue.value)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_statistic(session, settings, axis):\n",
    "    # Extract data\n",
    "    axis_label = 'x_axis' if axis == 'xAxis' else 'z_axis'\n",
    "    id = int(settings[axis]['value'])   \n",
    "    pivot_by = settings['pivotBy']\n",
    "    pivots = [value['value'] for value in pivot_by] if isinstance(pivot_by, list) else [pivot_by['value']]\n",
    "    years = [int(value['value']) for value in settings['years']]\n",
    "    states = [value['value'] for value in settings['states']]\n",
    "    # 1. Add group by selectors\n",
    "    group_selectors = []\n",
    "    aggregate_selector = None\n",
    "    for pivot in pivots:\n",
    "        group_selectors.append(stat_group_by_selectors[pivot])\n",
    "        aggregate_selector = stat_aggregate_selectors[pivot]\n",
    "    # 2. Create query\n",
    "    query = session.query(*group_selectors, aggregate_selector).\\\n",
    "        filter(StatisticsValue.statistics_id == id).\\\n",
    "        group_by(*group_selectors)\n",
    "    # 3. Filter by year\n",
    "    if len(years):\n",
    "        query = query.filter(StatisticsValue.year.in_(years))\n",
    "    # 4. Filter by state\n",
    "    if len(states):\n",
    "        query = query.filter(StatisticsValue.state.in_(states))\n",
    "    # Executing query and converting it to proper format\n",
    "    data = query.all()\n",
    "    result = {}\n",
    "    result['axis_label'] = axis_label\n",
    "    result[axis_label] = settings[axis]['display']\n",
    "    result['data'] = {}\n",
    "    for item in data:\n",
    "        item_data = result['data']\n",
    "        for sub_item in item[:-1]:        \n",
    "            item_data = item_data.setdefault(sub_item, {})\n",
    "        item_data[axis_label] = item[-1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_incidents(session, settings):\n",
    "    # Extracting values\n",
    "    inclusive_categories = [value['value'] for value in settings['inclusiveCategories']]\n",
    "    exclusive_categories = [value['value'] for value in settings['exclusiveCategories']]\n",
    "    years = [int(value['value']) for value in settings['years']]\n",
    "    states = [value['value'] for value in settings['states']]    \n",
    "    pivot_by = settings['pivotBy']\n",
    "    pivots = [value['value'] for value in pivot_by] if isinstance(pivot_by, list) else [pivot_by['value']]\n",
    "    y_axis = settings['yAxis']['value']\n",
    "    \n",
    "    # Check data type\n",
    "    has_participant_pivot = len(participant_pivots.intersection(pivots))\n",
    "    has_incident_pivot = len(incident_pivots.intersection(pivots))\n",
    "    has_incident_filter = len(inclusive_categories) or len(exclusive_categories) or len(years)\n",
    "    \n",
    "    # 1. Add group by selectors \n",
    "    group_selectors = []\n",
    "    group_converters = []\n",
    "    for pivot in pivots:\n",
    "        group_selectors.append(group_by_selectors[pivot])\n",
    "        group_converters.append(group_by_converters.get(pivot))\n",
    "    # 2. Add aggregate selector\n",
    "    aggregate_selector = func.count() if has_participant_pivot else incident_aggregate_selectors[y_axis]\n",
    "    query_selectors = group_selectors + [aggregate_selector]\n",
    "    query = session.query(*query_selectors)\n",
    "    # 3. Add join if both incidents and participants\n",
    "    if has_participant_pivot and (has_incident_pivot or has_incident_filter):\n",
    "        query = query.filter(Incident.id == Participant.incident_id)\n",
    "    # 4. Add participant type filters\n",
    "    for pivot in pivots:\n",
    "        is_participant = pivot in participant_pivots\n",
    "        if is_participant:\n",
    "            type_filter = participant_type_filters[pivot]\n",
    "            query = query.filter(type_filter[0] == type_filter[1])\n",
    "    # 5. Add participant status filters\n",
    "    if has_participant_pivot:    \n",
    "        status_filter = participant_status_filters[y_axis]\n",
    "        if status_filter:\n",
    "            query = query.filter(status_filter[0] == status_filter[1])\n",
    "    # 6. Add incident category filters\n",
    "    if len(inclusive_categories):\n",
    "        incat_incidents = session.query(Incident.id).\\\n",
    "            filter(Incident.categories.any(Category.name.in_(inclusive_categories))).\\\n",
    "            subquery()\n",
    "        query = query.join(incat_incidents, Incident.id == incat_incidents.c.id)\n",
    "    if len(exclusive_categories):\n",
    "        excat_incidents = session.query(Incident.id).\\\n",
    "            filter(Incident.categories.any(Category.name.in_(exclusive_categories))).\\\n",
    "            subquery()\n",
    "        query = query.outerjoin(excat_incidents, Incident.id == excat_incidents.c.id).\\\n",
    "            filter(excat_incidents.c.id == None)\n",
    "    # 7. Add filter to ignore items with unknown value\n",
    "    for group_selector in group_selectors:\n",
    "        query = query.filter(group_selector != None)\n",
    "    # 8. Add filter by years\n",
    "    if len(years):\n",
    "        query = query.filter(extract('year', Incident.date).in_(years))  \n",
    "    # 9. Filter by state\n",
    "    if len(states):\n",
    "        query = query.filter(Incident.state.in_(states))\n",
    "    # 10. Add group by\n",
    "    query = query.group_by(*group_selectors)\n",
    "    # Executing query and converting it to proper format\n",
    "    data = query.all()\n",
    "    result = {}\n",
    "    result['y_axis'] = settings['yAxis']['display']\n",
    "    result['pivot'] = [value['display'] for value in pivot_by] if isinstance(pivot_by, list) else [pivot_by['display']]\n",
    "    result['data'] = {}\n",
    "    for item in data:\n",
    "        item_data = result['data']\n",
    "        for i,sub_item in enumerate(item[:-1]):\n",
    "            item_data = item_data.setdefault(group_converters[i](sub_item) if group_converters[i] else sub_item, {})\n",
    "        item_data['y_axis'] = item[-1]\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(settings):\n",
    "    session = Session()\n",
    "    result = _get_incidents(session, settings)\n",
    "    x_axis = None\n",
    "    if 'xAxis' in settings:\n",
    "        x_axis = _get_statistic(session, settings, 'xAxis')\n",
    "        result['x_axis'] = settings['xAxis']['display']\n",
    "    z_axis = None\n",
    "    if 'zAxis' in settings:\n",
    "        z_axis = _get_statistic(session, settings, 'zAxis')\n",
    "        result['z_axis'] = settings['zAxis']['display']\n",
    "    for axis in [x_axis, z_axis]:\n",
    "        if not axis:\n",
    "            continue\n",
    "        axis_label = axis['axis_label']\n",
    "        result\n",
    "        # This algorithm treats the both incident dictionary and x- or z-axis dictionary as n-ary trees which \n",
    "        # structures are mirrored, so it matches\n",
    "        stack = []\n",
    "        stack.append((result['data'], axis['data']))\n",
    "        while len(stack):\n",
    "            inc_data, axis_data = stack.pop()\n",
    "            \n",
    "            if axis_label in axis_data:\n",
    "                inc_data[axis_label] = axis_data[axis_label]\n",
    "                if 'y_axis' not in inc_data:\n",
    "                    inc_data['y_axis'] = 0\n",
    "            else:\n",
    "                for k in axis_data:                    \n",
    "                    stack.append((inc_data.setdefault(k, {}), axis_data[k]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories():\n",
    "    return [c[0] for c in Session().query(Category.name).all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics():\n",
    "    return [ { 'id':c[0], 'name':c[1] } for c in Session().query(Statistics.id, Statistics.name).all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook data_retrieval.ipynb to Script\n",
      "[NbConvertApp] Writing 8808 bytes to data_retrieval.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to Script data_retrieval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
