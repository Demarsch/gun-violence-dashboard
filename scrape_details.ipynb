{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_details(url, n_killed, n_injured):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    results = soup.find_all('div', class_=\"region region-content\")\n",
    "    \n",
    "    # Loop through returned results\n",
    "    incedent_scrap = {\"date\" : \"\", \"state\" : \"\", \"n_killed\" : 0, \"n_injured\" : 0, \"incident_characteristics\" : \"\",\n",
    "                      \"participant_age\" : \"\", \"participant_gender\" : \"\", \"participant_status\" : \"\",\n",
    "                      \"participant_type\" : \"\"}\n",
    "\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "        incedent = result.h1.text\n",
    "        #print(incedent)\n",
    "\n",
    "        incedent_scrap[\"date\"] = result.h3.text\n",
    "        #print(\"---------------------------\")\n",
    "        #print(date)\n",
    "\n",
    "        #addresses = result.find_all('span')\n",
    "        #for address in addresses:\n",
    "            #print(address.text)\n",
    "\n",
    "        results2 = soup.select('div#block-system-main div')\n",
    "        for div in results2:\n",
    "            if div.h2 and div.h2.text == 'Location':\n",
    "                locations = div.find_all('span')\n",
    "                for i,location in enumerate(reversed(locations)):\n",
    "                    if location.text.startswith(\"Geolocation\"):\n",
    "                        continue\n",
    "                    if \",\" in location.text:\n",
    "                        citystate = location.text.split(\", \")\n",
    "                        incedent_scrap[\"state\"] += f\"{citystate[1]}\"\n",
    "                #print(incedent_scrap[\"state\"])\n",
    "\n",
    "        divs = result.select('div > div')\n",
    "        for div in divs:\n",
    "            if not div.h2:\n",
    "                continue\n",
    "\n",
    "                #print(div.h2.text)\n",
    "\n",
    "            if (div.h2.text == 'Participants'):\n",
    "                participants = div.find_all('ul')\n",
    "                for i,participant in enumerate(participants):\n",
    "                    participant_dic = {}\n",
    "                    demograpics = participant.find_all('li')                    \n",
    "                    pass\n",
    "                    for demo in demograpics:\n",
    "                        demosplit = demo.text.split(\": \")                    \n",
    "                        if demosplit[0]== \"Name\":\n",
    "                            continue\n",
    "                        if demosplit[0]== \"Age Group\":\n",
    "                            continue\n",
    "                        participant_dic[demosplit[0]]=demosplit[1]\n",
    "                    if \"Type\" in participant_dic:\n",
    "                        incedent_scrap[\"participant_type\"] += f\"{i}::{participant_dic['Type']}||\"\n",
    "                    else:\n",
    "                        incedent_scrap[\"participant_type\"] += f\"{i}::Unknown||\"\n",
    "\n",
    "                    if \"Age\" in participant_dic:\n",
    "                        incedent_scrap[\"participant_age\"] += f\"{i}::{participant_dic['Age']}||\"\n",
    "                    else:\n",
    "                        incedent_scrap[\"participant_age\"] += f\"{i}::Unknown||\"\n",
    "\n",
    "                    if \"Gender\" in participant_dic:\n",
    "                        incedent_scrap[\"participant_gender\"] += f\"{i}::{participant_dic['Gender']}||\"\n",
    "                    else:\n",
    "                        incedent_scrap[\"participant_gender\"] += f\"{i}::Unknown||\"\n",
    "\n",
    "                    if \"Status\" in participant_dic:\n",
    "                        incedent_scrap[\"participant_status\"] += f\"{i}::{participant_dic['Status']}||\"\n",
    "                    else:\n",
    "                        incedent_scrap[\"participant_status\"] += f\"{i}::Unknown||\"\n",
    "                #print(incedent_scrap[\"participant_type\"])\n",
    "                #print(incedent_scrap[\"participant_age\"])\n",
    "                #print(incedent_scrap[\"participant_gender\"])\n",
    "                #print(incedent_scrap[\"participant_status\"])\n",
    "\n",
    "            if (div.h2.text == 'Incident Characteristics'):\n",
    "                characteristics = div.find_all('ul')\n",
    "                for characteristic in characteristics:\n",
    "                    catagorys = characteristic.find_all('li')\n",
    "                    pass\n",
    "                    for catagory in catagorys:\n",
    "                        incedent_scrap[\"incident_characteristics\"] += f\"{catagory.text}||\"\n",
    "                #print(incedent_scrap[\"incident_characteristics\"])\n",
    "    return incedent_scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook scrape_details.ipynb to python\n",
      "[NbConvertApp] Writing 4090 bytes to scrape_details.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python scrape_details.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
